{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1btjRY1MSHlFkyUj-QzOQymQxM2ptRZFN","authorship_tag":"ABX9TyM+Ik9ja6JDghOy6uMdlqWW"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":323253,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":272328,"modelId":293304},{"sourceId":325255,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":273554,"modelId":294460}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{"id":"JSDdRWMghd-4"}},{"cell_type":"code","source":"","metadata":{"id":"hpZ66mosRMz-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\n\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"devflo\").project(\"rdd2022-ook7x\")\nversion = project.version(3)\ndataset = version.download(\"yolov12\")\n\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"laura-hjwf7\").project(\"pothole-at-night\")\nversion = project.version(1)\ndataset = version.download(\"yolov12\")\n\nimport os\nimport shutil\nimport glob\nimport random\nimport math\nimport yaml\n\n# ------------------ הגדרות ראשוניות ------------------\n# נתיבים לדאטה:\nnew_dataset_dir = \"/kaggle/working/Pothole-At-Night-1\"  # הדאטה החדש\nold_dataset_dir = \"/kaggle/working/RDD2022-3\"          # הדאטה הישן (אליו נעביר את הקבצים)\n\nsplits = [\"train\", \"valid\", \"test\"]\n\n# ------------------ שלב 1: עדכון תיוגים בדאטה החדש ------------------\nprint(\"Step 1: Updating labels in new dataset...\")\n\nfor split in splits:\n    labels_dir = os.path.join(new_dataset_dir, split, \"labels\")\n    if not os.path.isdir(labels_dir):\n        print(f\"Labels directory not found for split '{split}'. Skipping...\")\n        continue\n    for filename in os.listdir(labels_dir):\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(labels_dir, filename)\n            with open(file_path, \"r\") as f:\n                lines = f.readlines()\n            updated_lines = []\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) == 5:  # פורמט YOLO: <class> <x_center> <y_center> <width> <height>\n                    parts[0] = \"8\"  # שינוי ה-class_id ל-8\n                    updated_lines.append(\" \".join(parts) + \"\\n\")\n                else:\n                    updated_lines.append(line)\n            with open(file_path, \"w\") as f:\n                f.writelines(updated_lines)\n            print(f\"Updated labels in {file_path}\")\nprint(\"All labels in new dataset updated to class_id=8.\\n\")\n\n# ------------------ שלב 2: מיזוג הדאטה ------------------\nprint(\"Step 2: Merging new dataset into old dataset...\")\n\nfor split in splits:\n    new_images_dir = os.path.join(new_dataset_dir, split, \"images\")\n    new_labels_dir = os.path.join(new_dataset_dir, split, \"labels\")\n\n    old_images_dir = os.path.join(old_dataset_dir, split, \"images\")\n    old_labels_dir = os.path.join(old_dataset_dir, split, \"labels\")\n\n    # ודא שהתיקיות קיימות ביעד\n    os.makedirs(old_images_dir, exist_ok=True)\n    os.makedirs(old_labels_dir, exist_ok=True)\n\n    # העתקת תמונות מהדאטה החדש\n    if os.path.isdir(new_images_dir):\n        for file in os.listdir(new_images_dir):\n            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                src_path = os.path.join(new_images_dir, file)\n                dst_path = os.path.join(old_images_dir, file)\n                shutil.copy(src_path, dst_path)\n                print(f\"Copied image {src_path} -> {dst_path}\")\n    else:\n        print(f\"Images directory not found for split '{split}' in new dataset.\")\n\n    # העתקת תיוגים מהדאטה החדש\n    if os.path.isdir(new_labels_dir):\n        for file in os.listdir(new_labels_dir):\n            if file.endswith(\".txt\"):\n                src_path = os.path.join(new_labels_dir, file)\n                dst_path = os.path.join(old_labels_dir, file)\n                shutil.copy(src_path, dst_path)\n                print(f\"Copied label {src_path} -> {dst_path}\")\n    else:\n        print(f\"Labels directory not found for split '{split}' in new dataset.\")\n\nprint(\"New dataset merged successfully into old dataset.\\n\")\n\n# ------------------ שלב 3: יצירת מבנה סופי (חלוקה ל-train, valid, test) ------------------\nprint(\"Step 3: Splitting merged dataset into train, valid, and test sets...\")\n\n# נניח שהדאטה הממוזגת נמצאת ב-old_dataset (המשולב)\nfinal_root = \"/kaggle/working/final_dataset\"\nfor split in splits:\n    os.makedirs(os.path.join(final_root, split, \"images\"), exist_ok=True)\n    os.makedirs(os.path.join(final_root, split, \"labels\"), exist_ok=True)\n\n# איסוף כל קבצי התמונות ממיזוג הדאטה\nmerged_images_dir = os.path.join(old_dataset_dir, \"train\", \"images\")  # נניח שמיזוג התמונות בוצע ב-train\nall_images = glob.glob(os.path.join(merged_images_dir, \"*\"))\nrandom.shuffle(all_images)\ntotal = len(all_images)\ntrain_count = math.floor(total * 0.8)\nvalid_count = math.floor(total * 0.1)\n\ntrain_images = all_images[:train_count]\nvalid_images = all_images[train_count:train_count+valid_count]\ntest_images = all_images[train_count+valid_count:]\n\ndef copy_split(image_list, split):\n    for img_path in image_list:\n        filename = os.path.basename(img_path)\n        dest_img = os.path.join(final_root, split, \"images\", filename)\n        shutil.copy(img_path, dest_img)\n        print(f\"[{split}] Copied image: {filename}\")\n        # העתקת תיוגים – מניחים שקובץ התיוג שם זהה עם סיומת .txt\n        label_filename = os.path.splitext(filename)[0] + \".txt\"\n        src_label = os.path.join(os.path.dirname(img_path).replace(\"images\", \"labels\"), label_filename)\n        if os.path.exists(src_label):\n            dest_label = os.path.join(final_root, split, \"labels\", label_filename)\n            shutil.copy(src_label, dest_label)\n            print(f\"[{split}] Copied label: {label_filename}\")\n        else:\n            print(f\"[{split}] Label not found for image: {filename}\")\n\ncopy_split(train_images, \"train\")\ncopy_split(valid_images, \"valid\")\ncopy_split(test_images, \"test\")\nprint(\"Dataset successfully split into train, valid, and test sets.\\n\")\n\n# ------------------ שלב 4: יצירת קובץ YAML ------------------\nprint(\"Step 4: Writing dataset YAML file...\")\ndata_yaml = {\n    \"train\": \"../train/images\",\n    \"val\": \"../valid/images\",\n    \"test\": \"../test/images\",\n    \"nc\": 11,\n    \"names\": [\n        \"Alligator Crack\",\n        \"Block Crack\",\n        \"Construction Joint Crack\",\n        \"Crosswalk Blur\",\n        \"Lane Blur\",\n        \"Longitudinal Crack\",\n        \"Manhole\",\n        \"Patch Repair\",\n        \"Pothole\",\n        \"Transverse Crack\",\n        \"Wheel Mark Crack\"\n    ],\n    \"roboflow\": {\n        \"workspace\": \"devflo\",\n        \"project\": \"rdd2022-ook7x\",\n        \"version\": 3,\n        \"license\": \"CC BY 4.0\",\n        \"url\": \"https://universe.roboflow.com/devflo/rdd2022-ook7x/dataset/3\"\n    }\n}\n\nyaml_path = os.path.join(final_root, \"dataset.yaml\")\nwith open(yaml_path, \"w\") as f:\n    yaml.dump(data_yaml, f, sort_keys=False)\nprint(\"Dataset YAML file written to:\", yaml_path)\nprint(\"All steps completed successfully!\")\n","metadata":{"id":"ZAkstDmwKxn_","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:12:09.800385Z","iopub.execute_input":"2025-04-07T14:12:09.800727Z","execution_failed":"2025-04-07T14:34:01.248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ייצוא מודל יולו לפורמט אחר \n","metadata":{"id":"ib5mLO2fhbya"}},{"cell_type":"code","source":"import onnx2tf\n!pip install tflite-support\n\nmodel = YOLO(\"yolo12n.pt\")\nmodel = YOLO(\"/kaggle/working/road_safety_model/weights/best.pt\")\nmodel.export(format=\"tflite\",data = \"/kaggle/working/final_dataset/dataset.yaml\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:37:36.960279Z","iopub.execute_input":"2025-04-06T16:37:36.960707Z","iopub.status.idle":"2025-04-06T16:39:08.277047Z","shell.execute_reply.started":"2025-04-06T16:37:36.960672Z","shell.execute_reply":"2025-04-06T16:39:08.276196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tflite_support.metadata_writers import object_detector\nfrom tflite_support.metadata_writers import writer_utils\n\nMODEL_PATH = \"/kaggle/working/road_safety_model/weights/best_saved_model/best_float32.tflite\"\nLABEL_FILE = \"/kaggle/working/road_safety_model/weights/best_saved_model/metadata.yaml\"\nEXPORT_DIR = \"/kaggle/working/road_safety_model/weights\"\n\n# יוצר את metadata עם נרמול\nwriter = object_detector.MetadataWriter.create_for_inference(\n    model_buffer=open(MODEL_PATH, \"rb\").read(),\n    input_norm_mean=[127.5],\n    input_norm_std=[127.5],\n    label_file_paths=[LABEL_FILE]\n)\n\nmodel_with_metadata = writer.populate()\nwriter_utils.save_file(model_with_metadata, f\"{EXPORT_DIR}/new_model_with_metadata.tflite\")\n\nprint(\"✅ Metadata added! Saved as new_model_with_metadata.tflite\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:21:51.452464Z","iopub.execute_input":"2025-04-06T17:21:51.452799Z","iopub.status.idle":"2025-04-06T17:21:52.494000Z","shell.execute_reply.started":"2025-04-06T17:21:51.452773Z","shell.execute_reply":"2025-04-06T17:21:52.493280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# הנתיב הראשי שהגדרת באימון\nproject_dir = \"/kaggle/working\"\n\n# חיפוש בתיקיות שבתוך הפרויקט\nfolders = [os.path.join(project_dir, f) for f in os.listdir(project_dir) if os.path.isdir(os.path.join(project_dir, f))]\n\n# פילטר לפי תיקיות YOLO עם קבצי last.pt\nyolo_dirs = []\nfor folder in folders:\n    last_pt_path = os.path.join(folder, \"weights\", \"last.pt\")\n    if os.path.exists(last_pt_path):\n        yolo_dirs.append((folder, os.path.getmtime(last_pt_path)))  # שמירה עם זמן עדכון\n\n# מיון לפי זמן שמירה (האחרון למעלה)\nyolo_dirs.sort(key=lambda x: x[1], reverse=True)\n\n# הדפסת הנתיב האחרון אם קיים\nif yolo_dirs:\n    last_folder = yolo_dirs[0][0]\n    print(\"📁 YOLO last training folder found at:\")\n    print(last_folder)\n    print(\"🔥 last.pt path:\")\n    print(os.path.join(last_folder, \"weights\", \"last.pt\"))\nelse:\n    print(\"לא נמצא קובץ last.pt בסביבת העבודה.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:40:56.754078Z","iopub.execute_input":"2025-04-07T12:40:56.754367Z","iopub.status.idle":"2025-04-07T12:40:56.761888Z","shell.execute_reply.started":"2025-04-07T12:40:56.754346Z","shell.execute_reply":"2025-04-07T12:40:56.760930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# התקנת ספריות\n%pip install ultralytics\n\n# יבוא מודול + בדיקת מערכת\nfrom ultralytics import YOLO, checks\n\n\n\n\n\n# יבוא מודול + בדיקת מערכת\nfrom ultralytics import YOLO, checks\n\n\nmodel = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")\n# התחלת האימון\nresults = model.train(\n    data=\"/kaggle/working/final_dataset/dataset.yaml\",  # הנתיב המלא לקובץ הנתונים שלך\n    epochs=50,                  # יותר אפוקים ללמידה טובה בתנאים קשים\n    imgsz=540,                   # רזולוציה גבוהה – מאפשרת זיהוי פרטים קטנים\n    batch=0.60,\n    patience=15,\n    optimizer='SGD',\n    lr0=0.002,\n    lrf=0.01,\n    seed=42,\n    amp=True,\n    cache=\"disk\",\n    workers=8,\n    cos_lr=True,\n    warmup_epochs=3,\n    verbose=True,\n    save=True,\n    profile\t=True,\n    resume  = True,\n    device = 0\n)\n\n","metadata":{"id":"YZCksf5lMeXw","outputId":"59198249-7e94-46fd-b394-f189e24c30d7","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:52:33.276583Z","iopub.execute_input":"2025-04-07T15:52:33.276978Z","execution_failed":"2025-04-07T21:34:52.691Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.103)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.14)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nUltralytics 8.3.103 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/new_model/tensorflow2/default/1/best (9).pt, data=/kaggle/working/final_dataset/dataset.yaml, epochs=50, time=None, patience=15, batch=0.6, imgsz=540, save=True, save_period=-1, cache=disk, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=True, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.002, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 21        [14, 17, 20]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \nYOLOv12n summary: 272 layers, 2,570,193 parameters, 2,570,177 gradients, 6.5 GFLOPs\n\nTransferred 691/691 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\nWARNING ⚠️ imgsz=[540] must be multiple of max stride 32, updating to [544]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset/train/labels.cache... 66540 images, 19812 backgrounds, 0 corrupt: 100%|██████████| 66540/66540 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m114.2GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk ⚠️\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=544 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 13.07G reserved, 0.09G allocated, 1.58G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     2570193       4.689         1.812         50.36          42.5        (1, 3, 544, 544)                    list\n     2570193       9.379         1.850         42.94         45.69        (2, 3, 544, 544)                    list\n     2570193       18.76         1.883          45.2         47.28        (4, 3, 544, 544)                    list\n     2570193       37.52         2.082         40.54         68.23        (8, 3, 544, 544)                    list\n     2570193       75.03         3.280         57.18         111.6       (16, 3, 544, 544)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mWARNING ⚠️ batch=0 outside safe range, using default batch-size 16.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 16 for CUDA:0 15.92G/14.74G (108%) ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset/train/labels.cache... 66540 images, 19812 backgrounds, 0 corrupt: 100%|██████████| 66540/66540 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m114.2GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk ⚠️\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/final_dataset/valid/labels.cache... 8317 images, 2386 backgrounds, 0 corrupt: 100%|██████████| 8317/8317 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m14.3GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk ⚠️\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.002, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 544 train, 544 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      2.23G       1.46      1.407      1.332         77        544: 100%|██████████| 4159/4159 [14:55<00:00,  4.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:49<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.803      0.693      0.797      0.525\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50      2.26G      1.471      1.427      1.337         31        544: 100%|██████████| 4159/4159 [14:00<00:00,  4.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:47<00:00,  5.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642       0.77      0.702      0.789       0.51\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      2.26G      1.494      1.466      1.347         24        544: 100%|██████████| 4159/4159 [13:46<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:48<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642       0.77       0.69      0.764      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      2.27G       1.52      1.508      1.362         32        544: 100%|██████████| 4159/4159 [13:39<00:00,  5.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:48<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.696      0.693      0.741      0.484\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:49<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.734      0.694      0.753      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      2.27G       1.51      1.494      1.353         26        544:  15%|█▍        | 620/4159 [02:02<11:35,  5.09it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!ls /content/drive/MyDrive/saved_models/road_safety_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:33:56.805156Z","iopub.execute_input":"2025-04-07T12:33:56.805470Z","iopub.status.idle":"2025-04-07T12:33:57.016165Z","shell.execute_reply.started":"2025-04-07T12:33:56.805441Z","shell.execute_reply":"2025-04-07T12:33:57.015265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# בדיקת מודל על תמונה תיקייה או סרטון","metadata":{"id":"yLA9ZZq2hR-Y"}},{"cell_type":"markdown","source":"##משיכת מודל שמור מהדרייב אם יש","metadata":{"id":"89ca9mC8fFJT"}},{"cell_type":"code","source":"import os\nimport glob\nfrom google.colab import drive\n\n# חיבור ל-Google Drive\ndrive.mount('/content/drive')\n\n# נתיב לתיקיית המודלים\nmodels_dir = \"/content/drive/MyDrive/saved_models\"\n\n# רשימת סיומות חוקיות למודלים\nvalid_exts = [\".pt\", \".onnx\", \".pth\"]\n\n# חיפוש כל הקבצים החוקיים\nmodel_files = []\nfor ext in valid_exts:\n    model_files.extend(glob.glob(os.path.join(models_dir, f\"*{ext}\")))\n\n# בדיקה אם נמצאו מודלים\nif not model_files:\n    print(\"😕 No model files found in the folder.\")\nelse:\n    print(\"📦 Available models:\\n\")\n    for i, path in enumerate(model_files):\n        print(f\"{i + 1}. {os.path.basename(path)}\")\n\n    # בחירת מודל\n    while True:\n        try:\n            choice = int(input(\"\\n🔍 Enter the number of the model you want to load: \")) - 1\n            if 0 <= choice < len(model_files):\n                selected_model = model_files[choice]\n                print(f\"\\n✅ You selected: {selected_model}\")\n                break\n            else:\n                print(\"❌ Invalid choice. Try again.\")\n        except ValueError:\n            print(\"⚠️ Please enter a valid number.\")\n","metadata":{"id":"0RpDFa4ZfD23"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install ultralytics\nfrom ultralytics import YOLO\nmodel = YOLO(\"/road_damage_detection_last_version.pt\")\nresults = model.predict(\n    source='/content/drive/MyDrive/test_me/videos_only/IMG_6205.mov',\n    save=True,\n    save_txt=False,\n    conf=0.25\n)\n","metadata":{"id":"WILiClXIhNUl"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"laura-hjwf7\").project(\"pothole-at-night\")\nversion = project.version(1)\ndataset = version.download(\"yolov12\")\n","metadata":{"id":"rxO6QhCQ-XlZ"},"outputs":[],"execution_count":null}]}