{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1btjRY1MSHlFkyUj-QzOQymQxM2ptRZFN","authorship_tag":"ABX9TyM+Ik9ja6JDghOy6uMdlqWW"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":323253,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":272328,"modelId":293304},{"sourceId":325255,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":273554,"modelId":294460}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{"id":"JSDdRWMghd-4"}},{"cell_type":"code","source":"","metadata":{"id":"hpZ66mosRMz-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\n\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"devflo\").project(\"rdd2022-ook7x\")\nversion = project.version(3)\ndataset = version.download(\"yolov12\")\n\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"laura-hjwf7\").project(\"pothole-at-night\")\nversion = project.version(1)\ndataset = version.download(\"yolov12\")\n\nimport os\nimport shutil\nimport glob\nimport random\nimport math\nimport yaml\n\n# ------------------ ×”×’×“×¨×•×ª ×¨××©×•× ×™×•×ª ------------------\n# × ×ª×™×‘×™× ×œ×“××˜×”:\nnew_dataset_dir = \"/kaggle/working/Pothole-At-Night-1\"  # ×”×“××˜×” ×”×—×“×©\nold_dataset_dir = \"/kaggle/working/RDD2022-3\"          # ×”×“××˜×” ×”×™×©×Ÿ (××œ×™×• × ×¢×‘×™×¨ ××ª ×”×§×‘×¦×™×)\n\nsplits = [\"train\", \"valid\", \"test\"]\n\n# ------------------ ×©×œ×‘ 1: ×¢×“×›×•×Ÿ ×ª×™×•×’×™× ×‘×“××˜×” ×”×—×“×© ------------------\nprint(\"Step 1: Updating labels in new dataset...\")\n\nfor split in splits:\n    labels_dir = os.path.join(new_dataset_dir, split, \"labels\")\n    if not os.path.isdir(labels_dir):\n        print(f\"Labels directory not found for split '{split}'. Skipping...\")\n        continue\n    for filename in os.listdir(labels_dir):\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(labels_dir, filename)\n            with open(file_path, \"r\") as f:\n                lines = f.readlines()\n            updated_lines = []\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) == 5:  # ×¤×•×¨××˜ YOLO: <class> <x_center> <y_center> <width> <height>\n                    parts[0] = \"8\"  # ×©×™× ×•×™ ×”-class_id ×œ-8\n                    updated_lines.append(\" \".join(parts) + \"\\n\")\n                else:\n                    updated_lines.append(line)\n            with open(file_path, \"w\") as f:\n                f.writelines(updated_lines)\n            print(f\"Updated labels in {file_path}\")\nprint(\"All labels in new dataset updated to class_id=8.\\n\")\n\n# ------------------ ×©×œ×‘ 2: ××™×–×•×’ ×”×“××˜×” ------------------\nprint(\"Step 2: Merging new dataset into old dataset...\")\n\nfor split in splits:\n    new_images_dir = os.path.join(new_dataset_dir, split, \"images\")\n    new_labels_dir = os.path.join(new_dataset_dir, split, \"labels\")\n\n    old_images_dir = os.path.join(old_dataset_dir, split, \"images\")\n    old_labels_dir = os.path.join(old_dataset_dir, split, \"labels\")\n\n    # ×•×“× ×©×”×ª×™×§×™×•×ª ×§×™×™××•×ª ×‘×™×¢×“\n    os.makedirs(old_images_dir, exist_ok=True)\n    os.makedirs(old_labels_dir, exist_ok=True)\n\n    # ×”×¢×ª×§×ª ×ª××•× ×•×ª ××”×“××˜×” ×”×—×“×©\n    if os.path.isdir(new_images_dir):\n        for file in os.listdir(new_images_dir):\n            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                src_path = os.path.join(new_images_dir, file)\n                dst_path = os.path.join(old_images_dir, file)\n                shutil.copy(src_path, dst_path)\n                print(f\"Copied image {src_path} -> {dst_path}\")\n    else:\n        print(f\"Images directory not found for split '{split}' in new dataset.\")\n\n    # ×”×¢×ª×§×ª ×ª×™×•×’×™× ××”×“××˜×” ×”×—×“×©\n    if os.path.isdir(new_labels_dir):\n        for file in os.listdir(new_labels_dir):\n            if file.endswith(\".txt\"):\n                src_path = os.path.join(new_labels_dir, file)\n                dst_path = os.path.join(old_labels_dir, file)\n                shutil.copy(src_path, dst_path)\n                print(f\"Copied label {src_path} -> {dst_path}\")\n    else:\n        print(f\"Labels directory not found for split '{split}' in new dataset.\")\n\nprint(\"New dataset merged successfully into old dataset.\\n\")\n\n# ------------------ ×©×œ×‘ 3: ×™×¦×™×¨×ª ××‘× ×” ×¡×•×¤×™ (×—×œ×•×§×” ×œ-train, valid, test) ------------------\nprint(\"Step 3: Splitting merged dataset into train, valid, and test sets...\")\n\n# × × ×™×— ×©×”×“××˜×” ×”×××•×–×’×ª × ××¦××ª ×‘-old_dataset (×”××©×•×œ×‘)\nfinal_root = \"/kaggle/working/final_dataset\"\nfor split in splits:\n    os.makedirs(os.path.join(final_root, split, \"images\"), exist_ok=True)\n    os.makedirs(os.path.join(final_root, split, \"labels\"), exist_ok=True)\n\n# ××™×¡×•×£ ×›×œ ×§×‘×¦×™ ×”×ª××•× ×•×ª ×××™×–×•×’ ×”×“××˜×”\nmerged_images_dir = os.path.join(old_dataset_dir, \"train\", \"images\")  # × × ×™×— ×©××™×–×•×’ ×”×ª××•× ×•×ª ×‘×•×¦×¢ ×‘-train\nall_images = glob.glob(os.path.join(merged_images_dir, \"*\"))\nrandom.shuffle(all_images)\ntotal = len(all_images)\ntrain_count = math.floor(total * 0.8)\nvalid_count = math.floor(total * 0.1)\n\ntrain_images = all_images[:train_count]\nvalid_images = all_images[train_count:train_count+valid_count]\ntest_images = all_images[train_count+valid_count:]\n\ndef copy_split(image_list, split):\n    for img_path in image_list:\n        filename = os.path.basename(img_path)\n        dest_img = os.path.join(final_root, split, \"images\", filename)\n        shutil.copy(img_path, dest_img)\n        print(f\"[{split}] Copied image: {filename}\")\n        # ×”×¢×ª×§×ª ×ª×™×•×’×™× â€“ ×× ×™×—×™× ×©×§×•×‘×¥ ×”×ª×™×•×’ ×©× ×–×”×” ×¢× ×¡×™×•××ª .txt\n        label_filename = os.path.splitext(filename)[0] + \".txt\"\n        src_label = os.path.join(os.path.dirname(img_path).replace(\"images\", \"labels\"), label_filename)\n        if os.path.exists(src_label):\n            dest_label = os.path.join(final_root, split, \"labels\", label_filename)\n            shutil.copy(src_label, dest_label)\n            print(f\"[{split}] Copied label: {label_filename}\")\n        else:\n            print(f\"[{split}] Label not found for image: {filename}\")\n\ncopy_split(train_images, \"train\")\ncopy_split(valid_images, \"valid\")\ncopy_split(test_images, \"test\")\nprint(\"Dataset successfully split into train, valid, and test sets.\\n\")\n\n# ------------------ ×©×œ×‘ 4: ×™×¦×™×¨×ª ×§×•×‘×¥ YAML ------------------\nprint(\"Step 4: Writing dataset YAML file...\")\ndata_yaml = {\n    \"train\": \"../train/images\",\n    \"val\": \"../valid/images\",\n    \"test\": \"../test/images\",\n    \"nc\": 11,\n    \"names\": [\n        \"Alligator Crack\",\n        \"Block Crack\",\n        \"Construction Joint Crack\",\n        \"Crosswalk Blur\",\n        \"Lane Blur\",\n        \"Longitudinal Crack\",\n        \"Manhole\",\n        \"Patch Repair\",\n        \"Pothole\",\n        \"Transverse Crack\",\n        \"Wheel Mark Crack\"\n    ],\n    \"roboflow\": {\n        \"workspace\": \"devflo\",\n        \"project\": \"rdd2022-ook7x\",\n        \"version\": 3,\n        \"license\": \"CC BY 4.0\",\n        \"url\": \"https://universe.roboflow.com/devflo/rdd2022-ook7x/dataset/3\"\n    }\n}\n\nyaml_path = os.path.join(final_root, \"dataset.yaml\")\nwith open(yaml_path, \"w\") as f:\n    yaml.dump(data_yaml, f, sort_keys=False)\nprint(\"Dataset YAML file written to:\", yaml_path)\nprint(\"All steps completed successfully!\")\n","metadata":{"id":"ZAkstDmwKxn_","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:12:09.800385Z","iopub.execute_input":"2025-04-07T14:12:09.800727Z","execution_failed":"2025-04-07T14:34:01.248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ×™×™×¦×•× ××•×“×œ ×™×•×œ×• ×œ×¤×•×¨××˜ ××—×¨ \n","metadata":{"id":"ib5mLO2fhbya"}},{"cell_type":"code","source":"import onnx2tf\n!pip install tflite-support\n\nmodel = YOLO(\"yolo12n.pt\")\nmodel = YOLO(\"/kaggle/working/road_safety_model/weights/best.pt\")\nmodel.export(format=\"tflite\",data = \"/kaggle/working/final_dataset/dataset.yaml\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:37:36.960279Z","iopub.execute_input":"2025-04-06T16:37:36.960707Z","iopub.status.idle":"2025-04-06T16:39:08.277047Z","shell.execute_reply.started":"2025-04-06T16:37:36.960672Z","shell.execute_reply":"2025-04-06T16:39:08.276196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tflite_support.metadata_writers import object_detector\nfrom tflite_support.metadata_writers import writer_utils\n\nMODEL_PATH = \"/kaggle/working/road_safety_model/weights/best_saved_model/best_float32.tflite\"\nLABEL_FILE = \"/kaggle/working/road_safety_model/weights/best_saved_model/metadata.yaml\"\nEXPORT_DIR = \"/kaggle/working/road_safety_model/weights\"\n\n# ×™×•×¦×¨ ××ª metadata ×¢× × ×¨××•×œ\nwriter = object_detector.MetadataWriter.create_for_inference(\n    model_buffer=open(MODEL_PATH, \"rb\").read(),\n    input_norm_mean=[127.5],\n    input_norm_std=[127.5],\n    label_file_paths=[LABEL_FILE]\n)\n\nmodel_with_metadata = writer.populate()\nwriter_utils.save_file(model_with_metadata, f\"{EXPORT_DIR}/new_model_with_metadata.tflite\")\n\nprint(\"âœ… Metadata added! Saved as new_model_with_metadata.tflite\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:21:51.452464Z","iopub.execute_input":"2025-04-06T17:21:51.452799Z","iopub.status.idle":"2025-04-06T17:21:52.494000Z","shell.execute_reply.started":"2025-04-06T17:21:51.452773Z","shell.execute_reply":"2025-04-06T17:21:52.493280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# ×”× ×ª×™×‘ ×”×¨××©×™ ×©×”×’×“×¨×ª ×‘××™××•×Ÿ\nproject_dir = \"/kaggle/working\"\n\n# ×—×™×¤×•×© ×‘×ª×™×§×™×•×ª ×©×‘×ª×•×š ×”×¤×¨×•×™×§×˜\nfolders = [os.path.join(project_dir, f) for f in os.listdir(project_dir) if os.path.isdir(os.path.join(project_dir, f))]\n\n# ×¤×™×œ×˜×¨ ×œ×¤×™ ×ª×™×§×™×•×ª YOLO ×¢× ×§×‘×¦×™ last.pt\nyolo_dirs = []\nfor folder in folders:\n    last_pt_path = os.path.join(folder, \"weights\", \"last.pt\")\n    if os.path.exists(last_pt_path):\n        yolo_dirs.append((folder, os.path.getmtime(last_pt_path)))  # ×©××™×¨×” ×¢× ×–××Ÿ ×¢×“×›×•×Ÿ\n\n# ××™×•×Ÿ ×œ×¤×™ ×–××Ÿ ×©××™×¨×” (×”××—×¨×•×Ÿ ×œ××¢×œ×”)\nyolo_dirs.sort(key=lambda x: x[1], reverse=True)\n\n# ×”×“×¤×¡×ª ×”× ×ª×™×‘ ×”××—×¨×•×Ÿ ×× ×§×™×™×\nif yolo_dirs:\n    last_folder = yolo_dirs[0][0]\n    print(\"ğŸ“ YOLO last training folder found at:\")\n    print(last_folder)\n    print(\"ğŸ”¥ last.pt path:\")\n    print(os.path.join(last_folder, \"weights\", \"last.pt\"))\nelse:\n    print(\"×œ× × ××¦× ×§×•×‘×¥ last.pt ×‘×¡×‘×™×‘×ª ×”×¢×‘×•×“×”.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:40:56.754078Z","iopub.execute_input":"2025-04-07T12:40:56.754367Z","iopub.status.idle":"2025-04-07T12:40:56.761888Z","shell.execute_reply.started":"2025-04-07T12:40:56.754346Z","shell.execute_reply":"2025-04-07T12:40:56.760930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ×”×ª×§× ×ª ×¡×¤×¨×™×•×ª\n%pip install ultralytics\n\n# ×™×‘×•× ××•×“×•×œ + ×‘×“×™×§×ª ××¢×¨×›×ª\nfrom ultralytics import YOLO, checks\n\n\n\n\n\n# ×™×‘×•× ××•×“×•×œ + ×‘×“×™×§×ª ××¢×¨×›×ª\nfrom ultralytics import YOLO, checks\n\n\nmodel = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")\n# ×”×ª×—×œ×ª ×”××™××•×Ÿ\nresults = model.train(\n    data=\"/kaggle/working/final_dataset/dataset.yaml\",  # ×”× ×ª×™×‘ ×”××œ× ×œ×§×•×‘×¥ ×”× ×ª×•× ×™× ×©×œ×š\n    epochs=50,                  # ×™×•×ª×¨ ××¤×•×§×™× ×œ×œ××™×“×” ×˜×•×‘×” ×‘×ª× ××™× ×§×©×™×\n    imgsz=540,                   # ×¨×–×•×œ×•×¦×™×” ×’×‘×•×”×” â€“ ×××¤×©×¨×ª ×–×™×”×•×™ ×¤×¨×˜×™× ×§×˜× ×™×\n    batch=0.60,\n    patience=15,\n    optimizer='SGD',\n    lr0=0.002,\n    lrf=0.01,\n    seed=42,\n    amp=True,\n    cache=\"disk\",\n    workers=8,\n    cos_lr=True,\n    warmup_epochs=3,\n    verbose=True,\n    save=True,\n    profile\t=True,\n    resume  = True,\n    device = 0\n)\n\n","metadata":{"id":"YZCksf5lMeXw","outputId":"59198249-7e94-46fd-b394-f189e24c30d7","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:52:33.276583Z","iopub.execute_input":"2025-04-07T15:52:33.276978Z","execution_failed":"2025-04-07T21:34:52.691Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.103)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.14)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nUltralytics 8.3.103 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/new_model/tensorflow2/default/1/best (9).pt, data=/kaggle/working/final_dataset/dataset.yaml, epochs=50, time=None, patience=15, batch=0.6, imgsz=540, save=True, save_period=-1, cache=disk, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=True, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.002, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 21        [14, 17, 20]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \nYOLOv12n summary: 272 layers, 2,570,193 parameters, 2,570,177 gradients, 6.5 GFLOPs\n\nTransferred 691/691 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\nWARNING âš ï¸ imgsz=[540] must be multiple of max stride 32, updating to [544]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset/train/labels.cache... 66540 images, 19812 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66540/66540 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m114.2GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk âš ï¸\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=544 at 60.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 13.07G reserved, 0.09G allocated, 1.58G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     2570193       4.689         1.812         50.36          42.5        (1, 3, 544, 544)                    list\n     2570193       9.379         1.850         42.94         45.69        (2, 3, 544, 544)                    list\n     2570193       18.76         1.883          45.2         47.28        (4, 3, 544, 544)                    list\n     2570193       37.52         2.082         40.54         68.23        (8, 3, 544, 544)                    list\n     2570193       75.03         3.280         57.18         111.6       (16, 3, 544, 544)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mWARNING âš ï¸ batch=0 outside safe range, using default batch-size 16.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 16 for CUDA:0 15.92G/14.74G (108%) âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/final_dataset/train/labels.cache... 66540 images, 19812 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66540/66540 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m114.2GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk âš ï¸\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/final_dataset/valid/labels.cache... 8317 images, 2386 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8317/8317 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m14.3GB disk space required, with 50% safety margin but only 8.9/19.5GB free, not caching images to disk âš ï¸\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.002, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 544 train, 544 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      2.23G       1.46      1.407      1.332         77        544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4159/4159 [14:55<00:00,  4.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:49<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.803      0.693      0.797      0.525\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50      2.26G      1.471      1.427      1.337         31        544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4159/4159 [14:00<00:00,  4.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:47<00:00,  5.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642       0.77      0.702      0.789       0.51\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      2.26G      1.494      1.466      1.347         24        544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4159/4159 [13:46<00:00,  5.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:48<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642       0.77       0.69      0.764      0.492\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      2.27G       1.52      1.508      1.362         32        544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4159/4159 [13:39<00:00,  5.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:48<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.696      0.693      0.741      0.484\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:49<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       8317      14642      0.734      0.694      0.753      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      2.27G       1.51      1.494      1.353         26        544:  15%|â–ˆâ–        | 620/4159 [02:02<11:35,  5.09it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!ls /content/drive/MyDrive/saved_models/road_safety_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:33:56.805156Z","iopub.execute_input":"2025-04-07T12:33:56.805470Z","iopub.status.idle":"2025-04-07T12:33:57.016165Z","shell.execute_reply.started":"2025-04-07T12:33:56.805441Z","shell.execute_reply":"2025-04-07T12:33:57.015265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ×‘×“×™×§×ª ××•×“×œ ×¢×œ ×ª××•× ×” ×ª×™×§×™×™×” ××• ×¡×¨×˜×•×Ÿ","metadata":{"id":"yLA9ZZq2hR-Y"}},{"cell_type":"markdown","source":"##××©×™×›×ª ××•×“×œ ×©××•×¨ ××”×“×¨×™×™×‘ ×× ×™×©","metadata":{"id":"89ca9mC8fFJT"}},{"cell_type":"code","source":"import os\nimport glob\nfrom google.colab import drive\n\n# ×—×™×‘×•×¨ ×œ-Google Drive\ndrive.mount('/content/drive')\n\n# × ×ª×™×‘ ×œ×ª×™×§×™×™×ª ×”××•×“×œ×™×\nmodels_dir = \"/content/drive/MyDrive/saved_models\"\n\n# ×¨×©×™××ª ×¡×™×•××•×ª ×—×•×§×™×•×ª ×œ××•×“×œ×™×\nvalid_exts = [\".pt\", \".onnx\", \".pth\"]\n\n# ×—×™×¤×•×© ×›×œ ×”×§×‘×¦×™× ×”×—×•×§×™×™×\nmodel_files = []\nfor ext in valid_exts:\n    model_files.extend(glob.glob(os.path.join(models_dir, f\"*{ext}\")))\n\n# ×‘×“×™×§×” ×× × ××¦××• ××•×“×œ×™×\nif not model_files:\n    print(\"ğŸ˜• No model files found in the folder.\")\nelse:\n    print(\"ğŸ“¦ Available models:\\n\")\n    for i, path in enumerate(model_files):\n        print(f\"{i + 1}. {os.path.basename(path)}\")\n\n    # ×‘×—×™×¨×ª ××•×“×œ\n    while True:\n        try:\n            choice = int(input(\"\\nğŸ” Enter the number of the model you want to load: \")) - 1\n            if 0 <= choice < len(model_files):\n                selected_model = model_files[choice]\n                print(f\"\\nâœ… You selected: {selected_model}\")\n                break\n            else:\n                print(\"âŒ Invalid choice. Try again.\")\n        except ValueError:\n            print(\"âš ï¸ Please enter a valid number.\")\n","metadata":{"id":"0RpDFa4ZfD23"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install ultralytics\nfrom ultralytics import YOLO\nmodel = YOLO(\"/road_damage_detection_last_version.pt\")\nresults = model.predict(\n    source='/content/drive/MyDrive/test_me/videos_only/IMG_6205.mov',\n    save=True,\n    save_txt=False,\n    conf=0.25\n)\n","metadata":{"id":"WILiClXIhNUl"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\nproject = rf.workspace(\"laura-hjwf7\").project(\"pothole-at-night\")\nversion = project.version(1)\ndataset = version.download(\"yolov12\")\n","metadata":{"id":"rxO6QhCQ-XlZ"},"outputs":[],"execution_count":null}]}